{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import pandas as pd\n",
    "import emoji\n",
    "from collections import Counter\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "stopwords_set = set(stopwords.words(\"english\"))\n",
    "emojis = set(emoji.UNICODE_EMOJI[\"en\"].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The dataset is collected based on the __Constructing interval variables via faceted Rasch measurement and multitask deep learning: a hate speech application__ ([link](https://doi.org/10.48550/arxiv.2009.10277))._\n",
    "\n",
    "_I can be accessed through huggingface:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration ucberkeley-dlab--measuring-hate-speech-7cb9b0b8e4d0e1dd\n",
      "Reusing dataset parquet (/Users/badr/.cache/huggingface/datasets/parquet/ucberkeley-dlab--measuring-hate-speech-7cb9b0b8e4d0e1dd/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 121.09it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_dataset('ucberkeley-dlab/measuring-hate-speech', 'binary')   \n",
    "hate_speech_ucb = dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135556, 131)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_speech_ucb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The paper talks about the following categories by which the text is classified:_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](./column_table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Our goal is to classify hatespeech, so our objective is to predict the `hatespeech` label:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    80624\n",
       "2.0    46021\n",
       "1.0     8911\n",
       "Name: hatespeech, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_speech_ucb[\"hatespeech\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_In our dataset, the labels are organized like this:_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0 : no\n",
    "- 1 : unclear\n",
    "- 2 : yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "HATESPEECH_YES = 2\n",
    "HATESPEECH_NO = 0\n",
    "HATESPEECH_UNK = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Hate speech is defined in the paper as:__\n",
    "\n",
    "_Does this comment contain hate speech, defined as â€œbias-motivated, hostile and malicious language targeted at a person/group because of their actual or perceived innate characteristics, especially when the group is unnecessarily labeled (e.g., â€œjew bankersâ€, â€œnÃ¢Ä‚Åž hooligansâ€).â€ The comment contains hate speech if slurs or derogatory language are used toward any person or group regardless of whether or not the target is a member of the slur-target group. (e.g. a comment calling Trump a faggot or a n***** still contains hate speech)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A few text examples:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yes indeed. She sort of reminds me of the elder lady that played the part in the movie \"Titanic\" who was telling her story!!! And I wouldn\\'t have wanted to cover who I really am!! I would be proud!!!! WE should be proud of our race no matter what it is!!'\n",
      " 'The trans women reading this tweet right now is beautiful'\n",
      " 'It is about time for all illegals to go back to their country of origin and keep our freeway open and prevent heavy traffic.'\n",
      " \"Sounds like the kinda wholsesome life I'd die for â¤ï¸ never met any black Lesbians before so i guess you're my first ever.\"\n",
      " 'OMG! The EGO\\'s of these young, young, inexperienced women display are remarkable! So self absorbed - so, so proud of the mistakes their constituents all made in giving them a bit of power.  They\\'ll be quite surprised to find that the vast majority of Americans think that these women represent the very WORST of \"modern\" America.  Egos out of control !!'\n",
      " '9) uhhhh i like being lgbt a lot. i feel proud of what i have done to help others in my community'\n",
      " \"Instagram refugees lmao, let's build a wall instead\"\n",
      " '@terryelaineh1 @UKLabour Why do 3.8 million #50sWomen not constitute \"The Many\" not the few? Why is Labour not supporting women who\\'ve contributed all their working lives, paid for past pensions and NOW still paying, just for being women over 60! #BackTo60 #OneVoice #JudicialReview #CEDAW'\n",
      " 'I said it yesterday, I knew this is about to go down. Mangalore: Police now booked those Hindus who caught Ansari in the act of rap!ng that poor calf under sections 506, 504 (intentional insult with intent to provoke breach of peace), 323 & 153A. Judiciary is the most corrupt. URL'\n",
      " 'White Small Little Invisible Clits Are A Disgrace ðŸ¤¢ Pay Me For You Having Such a Small Disgraceful Useless Object  Kik GoddesssJayy  #Findom #Sph #Whiteslave #Humiliation #Pindick #Cashslave #Cuck #Cuckold #EbonyDomme']\n"
     ]
    }
   ],
   "source": [
    "print(hate_speech_ucb[hate_speech_ucb[\"hatespeech\"] == HATESPEECH_NO][\"text\"].iloc[:10].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Question: These 4 broads who criticize America, what country did they flee to get here? And now they want to make OUR America like THEIR former HELL HOLE. I don't think so!!!!!!!!!!  Let them explain their GRATITUDE for letting them in OUR country.\"\n",
      " \"For starters bend over the one in pink and kick that ass and pussy to get a taste until she's begging for a dick inside her.\"\n",
      " 'Who the fuck is this insignificant simple minded redneck? When he gets a vagina he can decide what he wants to do with it.'\n",
      " 'Fuck off you insufferable retarded faggot.'\n",
      " 'Worthless whore, these tits with look nice with bite marks and cum'\n",
      " '@suddenlywestan Because you are a country of mentally ill terrorists. Whoever says different is an enabler, ignorant and blind to endless/countless wars and aggression and the death rate by American terrorist acts. Fuck you American scum!'\n",
      " 'This sub is full of grade A faggots  Comedy fucking Ebola'\n",
      " 'Get rid of them and their anchor babies and grand babies. Fucking worthless guinees'\n",
      " '@KeGutta These niggas straight bitches' 'Da real white thug']\n"
     ]
    }
   ],
   "source": [
    "print(hate_speech_ucb[hate_speech_ucb[\"hatespeech\"] == HATESPEECH_YES][\"text\"].iloc[:10].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@ghostofthor same energy as the \"YOU DONT LOOK INDIAN STOP LYING ABOUT BEING SOUTH ASIAN\" cc'\n",
      " \"Y'all always slip up and say how y'all see women period because this includes the majority of women in yall lives that's not related to you. Especially since men demand pussy just from taking you out, selling you weed or even being nice to you. Niggas can't even be friends lol URL\"\n",
      " \"They wanna fuck so bad, just do it already, nobody cares if you're gay.\"\n",
      " \"Fuck Yeah ! Filthy Fuck'n Dirty Cock Cleanin' Sweat Fuck'n Drippin' Total Fuck'n Bottom Slut Christian Gettin' Gang Fuck'n Bred Hard and Fuck'n Rough for Balls Deep Fuck'n Loads of Filthy Fuck'n Dirty Cum Floodin' His Greedy Slutted Out Fuck'n Cunt (T.I.M)(Final Part) ðŸ‘ URL\"\n",
      " \"Are you people actually believing this propaganda.....  These ratchet women haven't done a thing , except spew hate and rhetoric....they are gonna get Saddamed...\"\n",
      " 'Bitches be salty as hell when a nigga treat they Ma dukes like a queen but not them ðŸ¤£'\n",
      " '@Cochis3 Not all the public, including Jews, are stupid enough to believe the absolute effluent spewed out by the Blairites Tories and media.'\n",
      " 'Canada a nation with great potential sold her soul to wickedness. She spent her billions dismembering human babies all over the world and dismembered 4 million of her own. God in his anger handed her over to a barbarous people who pride themselves on human dismemberment! ðŸ˜­ðŸ˜­ðŸ˜­'\n",
      " 'YOU 4 are Terrorists and will be leaving very soon! YOU 4 are Traitors and Obviously HATE Americans & OUR country #JihadSquad go quack your Fake outrage somewhere else...go to a muslim country you love islam so much you murder lover URL'\n",
      " 'I\\'m not saying you said that, I\\'m just saying that if you find a slur offensive (in this case the word niga) you\\'d find every other slur offensive. For me it\\'s the opposite, I find none of them offensive because unless the context is bad no one should give a shit. I can call my black friend \"niga\" in a friendly way or in an evil way. There\\'s a difference']\n"
     ]
    }
   ],
   "source": [
    "print(hate_speech_ucb[hate_speech_ucb[\"hatespeech\"] == HATESPEECH_UNK][\"text\"].iloc[:10].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_It's possible to see that the text in this data is very vulgar for all categories, that's why the definition of hatespeech in the paper is important, not all vulgar speech is hatespeech, and the goal of this dataset is to train a model that can make the distinction between the two._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A few statistics:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_emojis = 0\n",
    "word_counter = Counter()\n",
    "for sentence in dataset[\"train\"]:\n",
    "    tokens = tweet_tokenizer.tokenize(sentence[\"text\"])\n",
    "    if any([token in emojis for token in tokens]):\n",
    "        num_emojis += 1\n",
    "    word_counter.update([token.lower() for token in tokens if token.lower() not in stopwords_set and token.isalpha()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of emojis per text : 0.06553011301602289\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average number of emojis per text : {num_emojis / hate_speech_ucb.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('people', 22322),\n",
       " ('url', 19632),\n",
       " ('women', 16276),\n",
       " ('like', 15936),\n",
       " ('fuck', 14531),\n",
       " ('fucking', 14174),\n",
       " ('get', 13366),\n",
       " ('white', 13036),\n",
       " ('black', 10431),\n",
       " ('go', 9979),\n",
       " ('hate', 9551),\n",
       " ('men', 9235),\n",
       " ('bitch', 8600),\n",
       " ('one', 8133),\n",
       " ('back', 7913),\n",
       " ('even', 7877),\n",
       " ('need', 7202),\n",
       " ('niggers', 7134),\n",
       " ('country', 6885),\n",
       " ('know', 6824),\n",
       " ('would', 6720),\n",
       " ('human', 6636),\n",
       " ('stupid', 6537),\n",
       " ('every', 6509),\n",
       " ('u', 6388),\n",
       " ('muslims', 6192),\n",
       " ('want', 6180),\n",
       " ('see', 6150),\n",
       " ('right', 6138),\n",
       " ('gay', 6009),\n",
       " ('look', 5872),\n",
       " ('ass', 5789),\n",
       " ('world', 5631),\n",
       " ('kill', 5621),\n",
       " ('muslim', 5572),\n",
       " ('shit', 5407),\n",
       " ('die', 5199),\n",
       " ('think', 5170),\n",
       " ('make', 5127),\n",
       " ('america', 5103),\n",
       " ('us', 5004),\n",
       " ('pussy', 4907),\n",
       " ('god', 4626),\n",
       " ('love', 4562),\n",
       " ('nigger', 4443),\n",
       " ('many', 4343),\n",
       " ('trans', 4300),\n",
       " ('stop', 3958),\n",
       " ('really', 3895),\n",
       " ('racist', 3739)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_It's possible to confirm that the language in this dataset is vulgar and that would be a challenge when training because we cannot rely on vocabulary alone to classify._"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "489f32cec5ced41d911fff3541e240f4b3bf6c97086421ec046c82267ebe7e79"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
